{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raphaelzacharias/anaconda3/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/raphaelzacharias/anaconda3/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/raphaelzacharias/anaconda3/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/raphaelzacharias/anaconda3/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/raphaelzacharias/anaconda3/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/raphaelzacharias/anaconda3/envs/exts-ml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:absl:Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image generator\n",
    "##########################\n",
    "import os\n",
    "image_generator = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# A function that returns X_train,X_valid,...\n",
    "#############################################\n",
    "def get_data(target_size):\n",
    "    ## The training set\n",
    "    trainset = image_generator.flow_from_directory(\n",
    "        os.path.join('swissroads', 'train'),batch_size=280, target_size=(target_size,\n",
    "        target_size),shuffle=False)\n",
    "    X_train,y_train = trainset.next()\n",
    "    files_names_train = trainset.filenames\n",
    "    ## The valid set\n",
    "    validset = image_generator.flow_from_directory(\n",
    "        os.path.join('swissroads', 'valid'), batch_size=139,target_size=(target_size,\n",
    "        target_size),shuffle=False)\n",
    "    X_valid,y_valid = validset.next()\n",
    "    files_names_valid = validset.filenames\n",
    "    ## The test set\n",
    "    testset = image_generator.flow_from_directory(\n",
    "        os.path.join('swissroads', 'test'), batch_size=50,target_size=(target_size,\n",
    "        target_size),shuffle=False)\n",
    "    X_test,y_test = testset.next()\n",
    "    files_names_test = testset.filenames\n",
    "    ## Label's name\n",
    "    names = np.array(list(trainset.class_indices.keys()))\n",
    "    ## Return values\n",
    "    return X_train,X_valid,X_test,y_train,y_valid,y_test,files_names_train,files_names_valid,files_names_test,names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 images belonging to 6 classes.\n",
      "Found 139 images belonging to 6 classes.\n",
      "Found 50 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "## Original images\n",
    "##################\n",
    "X_train,X_valid,X_test,y_train,y_valid,y_test,files_names_train,files_names_valid,files_names_test,names  = get_data(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 images belonging to 6 classes.\n",
      "Found 139 images belonging to 6 classes.\n",
      "Found 50 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "## Images from which we extract high level features\n",
    "###################################################\n",
    "O_train,O_valid,O_test,_,_,_,_,_,_,_ = get_data(224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffle train and valid\n",
    "np.random.seed(0)\n",
    "idx_train = np.arange(len(y_train))\n",
    "idx_valid = np.arange(len(y_valid))\n",
    "np.random.shuffle(idx_train)\n",
    "np.random.shuffle(idx_valid)\n",
    "\n",
    "## train\n",
    "X_train = X_train[idx_train]\n",
    "y_train = y_train[idx_train]\n",
    "files_names_train = np.array(files_names_train)\n",
    "files_names_train = files_names_train[idx_train]\n",
    "O_train = O_train[idx_train]\n",
    "\n",
    "## valid\n",
    "X_valid = X_valid[idx_valid]\n",
    "y_valid = y_valid[idx_valid]\n",
    "files_names_valid = np.array(files_names_valid)\n",
    "files_names_valid = files_names_valid[idx_valid]\n",
    "O_valid = O_valid[idx_valid]\n",
    "\n",
    "## Change the shape of y\n",
    "y_train = np.argmax(y_train,axis=1)\n",
    "y_valid = np.argmax(y_valid,axis=1)\n",
    "y_test = np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Create graph\n",
    "img_graph = tf.Graph()\n",
    "\n",
    "with img_graph.as_default():\n",
    "    # Download module\n",
    "    module_url = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2'\n",
    "    feature_extractor = hub.Module(module_url)\n",
    "\n",
    "    # Create input placeholder\n",
    "    input_imgs = tf.placeholder(dtype=tf.float32, shape=[None, 224, 224, 3])\n",
    "\n",
    "    # A node with the features\n",
    "    imgs_features = feature_extractor(input_imgs)\n",
    "\n",
    "    # Collect initializers\n",
    "    init_op = tf.group([\n",
    "        tf.global_variables_initializer(), tf.tables_initializer()\n",
    "    ])\n",
    "\n",
    "img_graph.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  (280, 1280)\n",
      "valid :  (139, 1280)\n",
      "test :  (50, 1280)\n"
     ]
    }
   ],
   "source": [
    "# Create a session\n",
    "sess = tf.Session(graph=img_graph)\n",
    "\n",
    "# Initialize it\n",
    "sess.run(init_op)\n",
    "\n",
    "# Extract features\n",
    "features_train = sess.run(imgs_features, feed_dict={input_imgs: O_train})\n",
    "features_valid = sess.run(imgs_features, feed_dict={input_imgs: O_valid})\n",
    "features_test = sess.run(imgs_features, feed_dict={input_imgs: O_test})\n",
    "\n",
    "print('train : ',features_train.shape)\n",
    "print('valid : ',features_valid.shape)\n",
    "print('test : ',features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create npz files\n",
    "###################\n",
    "np.savez('data_train.npz', features=X_train, targets=y_train, highfeat=features_train,\n",
    "        names = names,filenames=files_names_train)\n",
    "np.savez('data_valid.npz', features=X_valid, targets=y_valid, highfeat=features_valid,\n",
    "        names =names,filenames=files_names_valid)\n",
    "np.savez('data_test.npz', features=X_test,targets=y_test, highfeat=features_test,\n",
    "        names=names,filenames=files_names_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
